{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4DYl9pB6rZTHJLNUy9SPF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m4a1carbin4/2022_ML_PHW1/blob/main/PHW1_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import list \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree \n",
        "from sklearn.linear_model import LogisticRegression #Import LogisticRegression \n",
        "from sklearn import svm #Import SVM \n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function \n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import KFold "
      ],
      "metadata": {
        "id": "NcX10KyZrPAC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset \n",
        "Data = pd.read_csv(\"breast-cancer-wisconsin.data\",names=['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']) \n",
        " \n",
        "Data = Data.apply(pd.to_numeric,errors='coerce').fillna(0) \n",
        " \n",
        "Data[\"Class\"] = Data.Class.map({2:0,4:1}) \n",
        " \n",
        "Data "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "Hb3IDJXGrV9O",
        "outputId": "9ce1bdcb-f443-420e-9e18-1d4a602fdfe9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
              "0               1000025                5                        1   \n",
              "1               1002945                5                        4   \n",
              "2               1015425                3                        1   \n",
              "3               1016277                6                        8   \n",
              "4               1017023                4                        1   \n",
              "..                  ...              ...                      ...   \n",
              "694              776715                3                        1   \n",
              "695              841769                2                        1   \n",
              "696              888820                5                       10   \n",
              "697              897471                4                        8   \n",
              "698              897471                4                        8   \n",
              "\n",
              "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
              "0                           1                  1                            2   \n",
              "1                           4                  5                            7   \n",
              "2                           1                  1                            2   \n",
              "3                           8                  1                            3   \n",
              "4                           1                  3                            2   \n",
              "..                        ...                ...                          ...   \n",
              "694                         1                  1                            3   \n",
              "695                         1                  1                            2   \n",
              "696                        10                  3                            7   \n",
              "697                         6                  4                            3   \n",
              "698                         8                  5                            4   \n",
              "\n",
              "     Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
              "0            1.0                3                1        1      0  \n",
              "1           10.0                3                2        1      0  \n",
              "2            2.0                3                1        1      0  \n",
              "3            4.0                3                7        1      0  \n",
              "4            1.0                3                1        1      0  \n",
              "..           ...              ...              ...      ...    ...  \n",
              "694          2.0                1                1        1      0  \n",
              "695          1.0                1                1        1      0  \n",
              "696          3.0                8               10        2      1  \n",
              "697          4.0               10                6        1      1  \n",
              "698          5.0               10                4        1      1  \n",
              "\n",
              "[699 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24fa9242-a8bb-46bc-ac30-5b7d320311e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample code number</th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>776715</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>841769</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>888820</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>897471</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>897471</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>699 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24fa9242-a8bb-46bc-ac30-5b7d320311e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24fa9242-a8bb-46bc-ac30-5b7d320311e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24fa9242-a8bb-46bc-ac30-5b7d320311e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NHEoTS_-rL1G"
      },
      "outputs": [],
      "source": [
        "\n",
        "def classification_Compare(data, model, K): \n",
        "    feature = data[['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', \n",
        "                    'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']] \n",
        "    feature = feature.to_numpy().astype(np.uint32) \n",
        "    label = data.Class \n",
        "    label = label.to_numpy().astype(np.uint32) \n",
        " \n",
        "    scaler = MinMaxScaler() \n",
        " \n",
        "    scaler.fit(feature) \n",
        " \n",
        "    kfold = KFold(n_splits=K) \n",
        " \n",
        "    cv_accuracy = [] \n",
        "    n_iter = 0 \n",
        " \n",
        "    for train_index, test_index in kfold.split(feature):  # Split the features data by the kfold number specified above \n",
        " \n",
        "        x_train, x_test = feature[train_index], feature[test_index] \n",
        "        y_train, y_test = label[train_index], label[test_index] \n",
        " \n",
        "        model.fit(x_train, y_train) \n",
        "        pred = model.predict(x_test) \n",
        "        n_iter += 1 \n",
        " \n",
        "        accuracy = np.round(accuracy_score(y_test, pred), 4)  # round to 4 decimal places \n",
        "        train_size = x_train.shape[0] \n",
        "        test_size = x_test.shape[0] \n",
        " \n",
        "        print('\\n#{0} Cross-validation accuracy : {1},  Training data size : {2},  Validation data size : {3}' \n",
        "              .format(n_iter, accuracy, train_size, test_size)) \n",
        "        cv_accuracy.append(accuracy) \n",
        " \n",
        "    for train_index, test_index in kfold.split(feature):  # Split Min_Max scaled featres data by kfold number specified above \n",
        " \n",
        "        x_train, x_test = feature[train_index], feature[test_index] \n",
        "        y_train, y_test = label[train_index], label[test_index] \n",
        " \n",
        "        x_train = scaler.transform(x_train) \n",
        "        x_test = scaler.transform(x_test) \n",
        " \n",
        "        model.fit(x_train, y_train) \n",
        "        pred = model.predict(x_test) \n",
        "        n_iter += 1 \n",
        " \n",
        "        accuracy = np.round(accuracy_score(y_test, pred), 4)  # round to 4 decimal places \n",
        "        train_size = x_train.shape[0] \n",
        "        test_size = x_test.shape[0] \n",
        " \n",
        "        print('\\n#{0} Min_Max_Scaler Cross-validation accuracy : {1},  Training data size : {2},  Validation data size : {3}' \n",
        "              .format(n_iter, accuracy, train_size, test_size)) \n",
        "        cv_accuracy.append(accuracy) \n",
        " \n",
        "    return cv_accuracy \n",
        " \n",
        " \n",
        "def make_model(K, data, case, **kwargs): \n",
        "    if (case == 1): \n",
        "        model = DecisionTreeClassifier(criterion=\"entropy\", splitter=kwargs.get('splitter', \"best\") \n",
        "                                       , max_depth=kwargs.get('max_depth', None) \n",
        "                                       , min_samples_split=kwargs.get('min_samples_split', 2) \n",
        "                                       , min_samples_leaf=kwargs.get('min_samples_leaf', 1) \n",
        "                                       , min_weight_fraction_leaf=kwargs.get('min_weight_fraction_leaf', 0.0) \n",
        "                                       , max_features=kwargs.get('max_features', None) \n",
        "                                       , random_state=kwargs.get('random_state', None) \n",
        "                                       , max_leaf_nodes=kwargs.get('max_leaf_nodes', None) \n",
        "                                       , min_impurity_decrease=kwargs.get('min_impurity_decrease', 0.0) \n",
        "                                       , class_weight=kwargs.get('class_weight', None) \n",
        "                                       , ccp_alpha=kwargs.get('ccp_alpha', 0.0)) \n",
        "        return classification_Compare(data, model, K) \n",
        "    elif (case == 2): \n",
        "        model = DecisionTreeClassifier(criterion=\"entropy\", splitter=kwargs.get('splitter', \"best\") \n",
        "                                       , max_depth=kwargs.get('max_depth', None) \n",
        "                                       , min_samples_split=kwargs.get('min_samples_split', 2) \n",
        "                                       , min_samples_leaf=kwargs.get('min_samples_leaf', 1) \n",
        "                                       , min_weight_fraction_leaf=kwargs.get('min_weight_fraction_leaf', 0.0) \n",
        "                                       , max_features=kwargs.get('max_features', None) \n",
        "                                       , random_state=kwargs.get('random_state', None) \n",
        "                                       , max_leaf_nodes=kwargs.get('max_leaf_nodes', None) \n",
        "                                       , min_impurity_decrease=kwargs.get('min_impurity_decrease', 0.0) \n",
        "                                       , class_weight=kwargs.get('class_weight', None) \n",
        "                                       , ccp_alpha=kwargs.get('ccp_alpha', 0.0)) \n",
        "        return classification_Compare(data, model, K) \n",
        "    elif (case == 3): \n",
        "        model = LogisticRegression(penalty=kwargs.get('penalty', 'l2') \n",
        "                                   , dual=kwargs.get('dual', False) \n",
        "                                   , tol=kwargs.get('tol', 1e-4) \n",
        "                                   , C=kwargs.get('C', 1.0) \n",
        "                                   , fit_intercept=kwargs.get('fit_intercept', True) \n",
        "                                   , intercept_scaling=kwargs.get('intercept_scaling', 1) \n",
        "                                   , class_weight=kwargs.get('class_weight', None) \n",
        "                                   , random_state=kwargs.get('random_state', None) \n",
        "                                   , solver=kwargs.get('solver', 'lbfgs') \n",
        "                                   , max_iter=kwargs.get('max_iter', 100) \n",
        "                                   , multi_class=kwargs.get('multi_class', 'auto') \n",
        "                                   , verbose=kwargs.get('verbose', 0) \n",
        "                                   , warm_start=kwargs.get('warm_start', False) \n",
        "                                   , n_jobs=kwargs.get('n_jobs', None) \n",
        "                                   , l1_ratio=kwargs.get('l1_ratio', None)) \n",
        "        return classification_Compare(data, model, K) \n",
        "    elif (case == 4): \n",
        "        model = svm.SVC(C=kwargs.get('C', 1.0), \n",
        "                        degree=kwargs.get('degree', 3), \n",
        "                        gamma=kwargs.get('gamma', 'scale'), \n",
        "                        coef0=kwargs.get('coef0', 0.0), \n",
        "                        shrinking=kwargs.get('shrinking', True), \n",
        "                        probability=kwargs.get('probability', False), \n",
        "                        tol=kwargs.get('tol', 1e-3), \n",
        "                        cache_size=kwargs.get('cache_size', 200), \n",
        "                        class_weight=kwargs.get('class_weight', None), \n",
        "                        verbose=kwargs.get('verbose', False), \n",
        "                        max_iter=kwargs.get('max_iter', -1), \n",
        "                        decision_function_shape=kwargs.get('decision_function_shape', 'ovr'), \n",
        "                        break_ties=kwargs.get('break_ties', False), \n",
        "                        random_state=kwargs.get('random_state', None)) \n",
        "        return classification_Compare(data, model, K) \n",
        "    else: \n",
        "        print('case error! (1~4)') \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list = [] \n",
        " \n",
        "def acc_test(acc_list): \n",
        "    print('\\n<DecisionTreeClassifier_gini>') \n",
        "    tmp = make_model(3,Data,1,max_depth=10,min_samples_split=3,max_features='sqrt') \n",
        "    acc_list.append(tmp) \n",
        " \n",
        "    print('\\n\\n<DecisionTreeClassifier_entropy>') \n",
        "    tmp = make_model(3,Data,2,max_depth=7,min_samples_split=2,max_features='sqrt') \n",
        "    acc_list.append(tmp) \n",
        " \n",
        "    print('\\n\\n<LogisticRegression>') \n",
        "    tmp = make_model(3,Data,3,random_state=30,max_iter=100) \n",
        "    acc_list.append(tmp) \n",
        " \n",
        "    print('\\n\\n<SVM>') \n",
        "    tmp = make_model(3,Data,4,random_state=20,max_iter=10) \n",
        "    acc_list.append(tmp) \n",
        " \n",
        "acc_test(acc_list) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_zE3K4nraIu",
        "outputId": "0487cd8c-5b48-4c81-9fb2-4020d341b7b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<DecisionTreeClassifier_gini>\n",
            "\n",
            "#1 Cross-validation accuracy : 0.8798,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#2 Cross-validation accuracy : 0.9313,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#3 Cross-validation accuracy : 0.9614,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#4 Min_Max_Scaler Cross-validation accuracy : 0.897,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#5 Min_Max_Scaler Cross-validation accuracy : 0.9056,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#6 Min_Max_Scaler Cross-validation accuracy : 0.97,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "\n",
            "<DecisionTreeClassifier_entropy>\n",
            "\n",
            "#1 Cross-validation accuracy : 0.927,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#2 Cross-validation accuracy : 0.9399,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#3 Cross-validation accuracy : 0.9442,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#4 Min_Max_Scaler Cross-validation accuracy : 0.9185,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#5 Min_Max_Scaler Cross-validation accuracy : 0.9528,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#6 Min_Max_Scaler Cross-validation accuracy : 0.9571,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "\n",
            "<LogisticRegression>\n",
            "\n",
            "#1 Cross-validation accuracy : 0.927,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#2 Cross-validation accuracy : 0.9614,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#3 Cross-validation accuracy : 0.9828,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#4 Min_Max_Scaler Cross-validation accuracy : 0.9227,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#5 Min_Max_Scaler Cross-validation accuracy : 0.9528,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#6 Min_Max_Scaler Cross-validation accuracy : 0.9914,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "\n",
            "<SVM>\n",
            "\n",
            "#1 Cross-validation accuracy : 0.9399,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#2 Cross-validation accuracy : 0.9442,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#3 Cross-validation accuracy : 0.9657,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#4 Min_Max_Scaler Cross-validation accuracy : 0.9356,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#5 Min_Max_Scaler Cross-validation accuracy : 0.7811,  Training data size : 466,  Validation data size : 233\n",
            "\n",
            "#6 Min_Max_Scaler Cross-validation accuracy : 0.8112,  Training data size : 466,  Validation data size : 233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all Accuracy \n",
        "print('\\n<Accuracy output for all models> \\n\\n[DecisionTreeGini] [DecisionTreeEntropy] [LogisticRegression] [SVM]\\n') \n",
        "print(acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPXtFYDIrejG",
        "outputId": "70525622-f1dc-4111-e54a-67e2c4ddf3ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<Accuracy output for all models> \n",
            "\n",
            "[DecisionTreeGini] [DecisionTreeEntropy] [LogisticRegression] [SVM]\n",
            "\n",
            "[[0.8798, 0.9313, 0.9614, 0.897, 0.9056, 0.97], [0.927, 0.9399, 0.9442, 0.9185, 0.9528, 0.9571], [0.927, 0.9614, 0.9828, 0.9227, 0.9528, 0.9914], [0.9399, 0.9442, 0.9657, 0.9356, 0.7811, 0.8112]]\n"
          ]
        }
      ]
    }
  ]
}